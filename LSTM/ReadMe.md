#### RNN LSTM regression
* 1 hidden layer
    * Adjusable hidden cell count
* Unbounded output node
* Xavier initialization

#### TODO
* ~~Dynamic learning rate~~
* ~~Gradient check~~
* ~~Abstract squash function derivative for gradeint descent calculation~~
* Model parameter import/export
* ~~LSTM!~~

#### Note
* Change `RNN_RAND_SEED` in RNN.c for difference initial model parameter 

#### Reference
* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/
* [LSTM: A Search Space Odyssey](https://arxiv.org/abs/1503.04069)
